%%% Please, do not change any of the following parameters.
\documentclass[10pt,journal,compsoc,twoside]{IEEEtran}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{amsmath}
%\interdisplaylinepenalty=2500
\usepackage{algorithmic}
\usepackage{array}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{url}
\usepackage{lipsum}
\usepackage{hyperref}
\hypersetup{pdfborder = 0 0 0}
\PassOptionsToPackage{hyphens}{url}\usepackage{hyperref}
\newcommand{\Ref}[2]{#2 \ref{#1}}
\newcommand{\fromto}[5]{(#1 #3 $<$ #4 $<$ #2 #3)}
\graphicspath{ {figures/} } %%% put all images file into "figures/" subdirectory
\usepackage[detect-all]{siunitx}
\newcommand{\me}{\mathrm{e}}

\begin{document}

\title{Emotion recognition in computer games and films}

\author{Filip Rynkiewicz%
\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem lodz university of technology, Lodz, Poland, \hfil\break 	filip.rynkiewicz@dokt.p.lodz.pl}}


% The paper headers
\markboth{Computer Game Innovations, 2017}%
{}

\IEEEtitleabstractindextext{%
\begin{abstract}
%%% 100 words
In last years technology used in game and film creations has formed need to check reaction of users on watched image. Human body react on external stimulus by face microchanges, distortions in electroencephalography, pupil adjustments etc. Those processes can be recorded by specified apparatus thus correct analysis of those characteristics can be automated. Thanks to this authors are able to check reaction of viewers on their creations, or even construct algorithms that can do it automatically.

\end{abstract}

\begin{IEEEkeywords}
 emotion recognition, pupil reflex, EEG, electroencephalography, emotion clasificcation
\end{IEEEkeywords}}

\maketitle
\IEEEdisplaynontitleabstractindextext
\IEEEpeerreviewmaketitle
\IEEEraisesectionheading{
\section{Introduction}
}
Studies on recognition of the human emotions can be useful at many areas. Starting with psychology studies on behavioural disorder with patient that have problems with expressing emotions, through biology studies on creation of emotions in human body and ending with getting feedback from watched movie. Emotions allows to decide if user like what he see or not. That gives them an opportunity to choose if he wants to end it immediately, or even repeat those emotions again. For artists this informations is very desirable, because they can refine theirs creations based on information gathered under the influence of the viewer's reaction. Thanks to those researches artist will know when user will be more interest in action, and where it will be more dull or touching for them. 

In \cite{OrtonyCloreCollins1988} authors are creating theory witch explain generation of emotions in human body. They simplify it to few steps, like in algorithm. First there is a perception of an event then analysis of it based on user's own experience and norms, so finally the event could be classified as certain emotion.

Emotions can be detected by certain characteristics that could be classified to two groups:
\begin{itemize}
	\item psychological:
	\begin{itemize}
		\item EEG(electroencephalography),
		\item EMG(electromyography), 
		\item EKG(electrocardiography), 
		\item pupil diameter.
	\end{itemize} 
	\item non-psychological: 
	\begin{itemize} 
		\item text, 
		\item speech,
		\item  gestures, 
		\item facial expressions.
	\end{itemize}
\end{itemize}
This paper will be focused on group of psychological signals, especially on EEG and pupil diameter. It will be explained how to detect certain emotion based on fusions of the stimuli. There are plenty of researches where authors combine EEG with pupil diameter or even with eye trackers data, and those combined methods are more reliable and with better accuracy then individual ones \cite{WeiLongBoNanBaoLiang2014,CalvoDMello2010,SoleymaniPanticPun2002}. 
\section{EEG}
One of the most popular methods of emotion recognition are based on analysis of electroencephalography signals. Numerous researches\cite{LinMusic,GaoMehmood,NieWangShiLu} has shown that the brain activity, which EEG collect, is the most reliable source for emotion recognition. Main core of those studies is to find brain regions and frequency bands most related to those emotions. Studies of \cite{SarloBuodoPoliPalomba} showed that activation for unpleasant emotions was prominent over the right posterior regions in the alpha band. In \cite{SchmidtTrainor2001} authors found that frontal brain electrical activity is closely related to musical emotions, and in \cite{LiLu2009} authors confirmed theory that gamma band is also related to music emotions.
\subsection{Subjects and stimuli}
Using variety of movie clips, especially selected to those research and shown to participators, the EEG signals was recorded. Key feature of those movie clips is to cover different emotional responses to get results as best and accurate as possible. Psychologists recommended videos from 1 to 10 minutes long for elicitation of single emotion\cite{SchaeferNilsSanchezPhilippot2010}.

\subsection{Data acquisition} 


Gathering data of brain activity is done be special EEG cap, where \textit{AgCl} electrodes placed on it are collecting brain activity in certain areas. Most common used layout of electrodes is 10-20 system, shown in \Ref{fig:1020electrodes}{Figure}.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.7\linewidth]{10_20_electrodes}
	\caption{The EEG cap arrangement for 10-20 system.\cite{JirayucharoensakSuwichaPanngumIsrasenaPasin2014}}
	\label{fig:1020electrodes}
\end{figure}

Signals were recorder mostly in \numrange[range-phrase = --]{1000}{1024} Hz sampling rate. To speed up calculations those characteristics were down sampled to \numrange[range-phrase = --]{200}{256} Hz. Noises and artefacts reduction were done by applying bypass filter between  \numrange{0.5}{70} Hz.
\subsection{Data extraction}
Correlation of certain spectral power of EEG signal and emotions relevant processing was observed \cite{AftanasSavotinaMakhnev2005}. There are multiple methods of extracting power spectral density (PSD) from raw signals. Two of them will be expounded.

First \cite{WeiLongBoNanBaoLiang2014} use Fourier transform and Welch algorithm. This method split signal into overlapping segments and the PSD is estimated by averaging the periodograms, in result the power spectrum is smoother. PSD of individual electrode was estimated using 15s long windows with 50 percent overlapping. PSD bands like theta \fromto{4}{8}{Hz}{f} \  ,  slow alpha \fromto{6}{10}{Hz}{f} \  ,  alpha \fromto{8}{12}{Hz}{f} \  ,  beta \fromto{12}{30}{Hz}{f} \\  and  gamma 30Hz $<$ f were extracted from electrodes. In additional 14 symmetrical pairs on the right and left hemisphere was extracted to measure possible asymmetry in brain activity.
\newline
\newline
Second one use more short-time Fourier transform with non-overlapped Hanning window of 4 s. In addition to PSD the differential entropy (DE), differential asymmetry (DASM) and rational asymmetry (RASM) were extracted and compared. Like in first method five frequency bands was used. Delta \fromto{1}{3}{Hz}{f} \  ,  theta \fromto{4}{7}{Hz}{f} \  ,  alpha \fromto{8}{13}{Hz}{f} \  ,  beta \fromto{14}{30}{Hz}{f} \\ and  gamma \fromto{31}{50}{Hz}{f} \,. Using \Ref{eq:DE}{equation}, DE was calculated.
\begin{equation}
\begin{aligned}
h(X)=\int\limits_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi\sigma^{2}}}exp \frac{(x - \mu)^{2}}{2\sigma^{2}}log\frac{1}{\sqrt{2\pi\sigma^{2}}}\\ exp\frac{(x - \mu)^{2}}{2\sigma^{2}}dx = \frac{1}{2}log2\pi \me \sigma^{2}
\end{aligned}
\label{eq:DE}
\end{equation}
where X is Gauss distribution $N(\mu, \sigma^2)$, \textit{x} is a variable $\pi$ and $\me$ are constants. DASM and RASM are defined as :
\begin{equation}
DASM = h(X_{LEFT}) - h(X_{RIGHT})
\end{equation}
\begin{equation}
RASM = h(X_{LEFT}) / h(X_{RIGHT})
\end{equation}
where $X_{LEFT}$ and$X_{RIGHT}$ are DE features of left and right hemisphere of brain.
\newpage
\subsection{Classification}
After the data was collected and extracted the support vector machine (SVM) was used as classifier, in both examples.
In  \cite{WeiLongBoNanBaoLiang2014} they smoothing features using linear dynamic system (LDS).

\begin{figure}[ht]
	\centering
	\includegraphics[width=1.0\linewidth]{performanceOfClassifier1}
	\caption{The performance of classifiers using different kinds of frequency band features. For \cite{WeiLongBoNanBaoLiang2014}.}
	\label{fig:performanceofclassifier1}
\end{figure}
Result of classification can be bee seen at \Ref{fig:performanceofclassifier1}{Figure}. ASM feature is concatenation of DASM nad RASM. As we can see, Delta and Gamma frequency bands perform better than Theta and Alpha frequency bands, and total frequency band has a stable and  prominent  accuracy.  Also  we  can  find  that,  differential entropy features get best accuracies in almost all frequency  bands  except  Theta  band  (47.98\%  of  DE  features is  less  than  51.87\%  of  PSD  features).
\newline
\par In \cite{SoleymaniPanticPun2002} in EEG there was only DE feature. They have used SVM classification with RBF kernel.

\section{Pupil diameter}
Th second method is the analysis of the pupil diameter \cite{ZhaiBarreto}. 


\section{Multimodial Fusion}
\section{Conclusion}

Emotions are sophisticated mechanism in human body, but knowledge how they work can be helpful in many areas. Those signals can be obtained from many of human impulses, such as pupil reflex or brain signals. Using appropriate techniques and devices those characteristics can be collected and analysed to detect emotions.
	




\begin{thebibliography}{99}
\bibitem{OrtonyCloreCollins1988}A. Ortony, G.L. Clore, A. Collins \textit{The Cognitive Structure of Emotions.}, Cambridge University Press, July 1988.
\bibitem{CalvoDMello2010} R. A. Calvo, S.D'Mello \textit{Affect detection: An interdisciplinary review of models, methods and their applications}, IEEEE Transactions on Affective Computing, vol 1, no1, pp 18-37, 2010
\bibitem{SoleymaniPanticPun2002} M. Soleymani, M. Pantic, T. Pun \textit{Multimodal Emotion Recognition in Responce to Videos}, IEEE Transaction on Affective Computing, vol. 3, no. 2, april-June 2012
\bibitem{AdolphsTranesDamasio2003}R. Adolphs, D. Tranel, A.R. Damasio, \textit{Dissociable Neural Systems for Recognizing Emotions}, Brain and Cognition, vol. 52, no. 1, pp. 61-69, June 2003.
\bibitem{DamasioGrabowski2000} A.R. Damasio, T.J. Grabowski, A. Bechara, H. Damasio, L.L.B.
Ponto, J. Parvizi, and R.D. Hichwa, \textit{Subcortical and Cortical Brain
Activity during the Feeling of Self-Generated Emotions}, Nature
Neuroscience, vol. 3, no. 10, pp. 1049-1056, Oct. 2000.
\bibitem{WeiLongBoNanBaoLiang2014} Z. Wei-Long, D. Bo-Nan , L. Bao-Liang 
\textit{Multimodal Emotion Recognition using EEG and Eye Tracking Data}, IEEE, 2014
\bibitem{LinMusic}
Y. P. Lin et al., "EEG-Based Emotion Recognition in Music Listening," in IEEE Transactions on Biomedical Engineering, vol. 57, no. 7, pp. 1798-1806, July 2010.
doi: 10.1109/TBME.2010.2048568
\url{http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5458075&isnumber=5484937}
\bibitem{GaoMehmood}
Y. Gao, H. J. Lee and R. M. Mehmood, "Deep learninig of EEG signals for emotion recognition," 2015 IEEE International Conference on Multimedia \& Expo Workshops (ICMEW), Turin, 2015, pp. 1-5.
doi: 10.1109/ICMEW.2015.7169796
\url{http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7169796&isnumber=7169738}
\bibitem{NieWangShiLu}Dan Nie, Xiao-Wei Wang, Li-Chen Shi, and Bao-Liang Lu, EEG-based Emotion Recognition during Watching Movies, Proceedings of the 5th International IEEE EMBS Conference on Neural Engineering Cancun, Mexico, April 27 - May 1, 2011 ,\url{https://pdfs.semanticscholar.org/6511/590bc9677922c82747b5d183383f46b50db6.pdf}

\bibitem{ZhaiBarreto}
J. Zhai and A. Barreto, "Stress Detection in Computer Users Based on Digital Signal Processing of Noninvasive Physiological Variables," 2006 International Conference of the IEEE Engineering in Medicine and Biology Society, New York, NY, 2006, pp. 1355-1358.
doi: 10.1109/IEMBS.2006.259421
\url{ http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4462012&isnumber=4461641}

\bibitem{SarloBuodoPoliPalomba}
 M. Sarlo, G. Buodo, S. Poli, and D. Palomba, ”Changes in EEG alpha
power to different disgust elicitors: the specificity of mutilations,”
Neuroscience Letters, vol. 382, no.3, pp. 291-296, 2005.

\bibitem{SchmidtTrainor2001}
 L. A. Schmidt, and L. J. Trainor, ”Frontal brain electrical activity
distinguishes valence and intensity of musical emotions,” Cognition
and Emotion, vol. 15, no. 4, pp. 487-500, 2001.
\bibitem{LiLu2009}
M. Li, and B. L. Lu, ”Emotion classification based on gamma-band
EEG,” IEEE Int. Conf. Engineering in Medicine and Biology Society,
Minneapolis, 2009, pp. 1223-1226.
\bibitem{JirayucharoensakSuwichaPanngumIsrasenaPasin2014}
Jirayucharoensak, Suwicha  Pan-ngum, Setha  Israsena, Pasin. (2014). EEG-Based Emotion Recognition Using Deep Learning Network with Principal Component Based Covariate Shift Adaptation. TheScientificWorldJournal. 2014. 627892. 10.1155/2014/627892.
 \bibitem{SchaeferNilsSanchezPhilippot2010}
Alexandre   Schaefer  and  Frédéric   Nils  and  Xavier   Sanchez  and  Pierre   Philippot,
Assessing the effectiveness of a large database of emotion-eliciting films: A new tool for emotion researchers, 2010
\url{http://dx.doi.org/10.1080/02699930903274322}
\bibitem{AftanasSavotinaMakhnev2005}
Aftanas, L.I., Savotina, L.N., Makhnev, V.P. et al. Neurosci Behav Physiol (2005) 35: 951.\url{ https://doi.org/10.1007/s11055-005-0151-9}

\end{thebibliography}



\end{document}


