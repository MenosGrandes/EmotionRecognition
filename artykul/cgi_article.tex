%%% Please, do not change any of the following parameters.
\documentclass[10pt,journal,compsoc,twoside]{IEEEtran}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{amsmath}
%\interdisplaylinepenalty=2500
\usepackage{algorithmic}
\usepackage{array}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{url}
\usepackage{lipsum}
\usepackage[breaklinks]{hyperref}
\hypersetup{pdfborder = 0 0 0}
\PassOptionsToPackage{hyphens}{url}\usepackage{hyperref}
%ADDED
\usepackage[figurename=Tabela\:]{caption}
\def\UrlBreaks{\do\/\do-\do_}
\newcommand{\me}{\mathrm{e}}


\graphicspath{ {figures/} } %%% put all images file into "figures/" subdirectory



\begin{document}

\title{Emotion recognition in computer games and films.}

\author{Filip Rynkiewicz%
\IEEEcompsocitemizethanks{\IEEEcompsocthanksitem Politechnika Łódzka, Łódź, Polska, \hfil\break 	filip.rynkiewicz@dokt.p.lodz.pl}}


% The paper headers
\markboth{Computer Game Innovations, 2017}%
{}

\IEEEtitleabstractindextext{%
\begin{abstract}
%%% 100 words
In last years technology used in game and film creations has formed need to check reaction of users on watched image. Human body react on external stimulus by face microchanges, distortions in electroencephalography, pupil adjustments etc. Those processes can be recorded by specified apparatus thus correct analysis of those characteristics can be automated. Thanks to this authors are able to check reaction of viewers on their creations, or even construct algorithms that can do it automatically.

\end{abstract}

\begin{IEEEkeywords}
emotion recognition, pupil reflex, EEG, electroencephalography, emotion clasificcation
\end{IEEEkeywords}}

\maketitle
\IEEEdisplaynontitleabstractindextext
\IEEEpeerreviewmaketitle
\IEEEraisesectionheading{
\section{Introduction}
}
Emotions allows to decide if user like what he see or not. That gives them an opportunity to choose if he wants to end it immediately, or even repeat those emotions again. For artists this informations is very desirable, because they can refine theirs creations based on information gathered under the influence of the viewer's reaction. Thanks to those researches artist will know when user will be more interest in action, and where it will be more dull or touching for them. 

Human emotions are generated with a certain algorithm \cite{OrtonyCloreCollins1988}. First there is a perception of an event then analysis of it based on user's own experience and norms, so finally the event could be classified as certain emotion.

Emotions can be detected by certain characteristics that could be classified to two groups \cite{CalvoDMello2010}
\begin{itemize}
	\item psychological
	\begin{itemize}
		\item EEG(electroencephalography),
		\item EMG(electromyography), 
		\item EKG(electrocardiography), 
		\item pupil diameter.
	\end{itemize} 
	\item non-psychological: 
	\begin{itemize} 
		\item text, 
		\item speech,
		\item  gestures, 
		\item facial expressions.
	\end{itemize}
\end{itemize}

Most popular methods on emotion recognition is EEG. Numerous researches\cite{LinMusic,GaoMehmood,NieWangShiLu} has shown that the brain activity, which EEG collect, is the most reliable source for emotion recognition. 




\section{EEG}
\section{Pupil diameter}

\section{Conclusion}
Emotions are sophisticated mechanism in human body, but knowledge how they work can be helpful in many areas. Those signals can be obtained from many of human impulses, such as pupil reflex or brain signals. Using appropriate techniques and devices those characteristics can be collected and analysed to detect emotions.
	




\begin{thebibliography}{99}
\bibitem{OrtonyCloreCollins1988}A. Ortony, G.L. Clore, A. Collins \textit{The Cognitive Structure of Emotions.}, Cambridge University Press, July 1988.
\bibitem{CalvoDMello2010} R. A. Calvo, S.D'Mello \textit{Affect detection: An interdisciplinary review of models, methods and their applications}, IEEEE Transactions on Affective Computing, vol 1, no1, pp 18-37, 2010
\bibitem{SoleymaniPanticPun2002} M. Soleymani, M. Pantic, T. Pun \textit{Multimodal Emotion Recognition in Responce to Videos}, IEEE Transaction on Affective Computing, vol. 3, no. 2, april-June 2012
\bibitem{AdolphsTranesDamasio2003}R. Adolphs, D. Tranel, A.R. Damasio, \textit{Dissociable Neural Systems for Recognizing Emotions}, Brain and Cognition, vol. 52, no. 1, pp. 61-69, June 2003.
\bibitem{DamasioGrabowski2000} A.R. Damasio, T.J. Grabowski, A. Bechara, H. Damasio, L.L.B.
Ponto, J. Parvizi, and R.D. Hichwa, \textit{Subcortical and Cortical Brain
Activity during the Feeling of Self-Generated Emotions}, Nature
Neuroscience, vol. 3, no. 10, pp. 1049-1056, Oct. 2000.
\bibitem{WeiLongBoNanBaoLiang2014} Z. Wei-Long, D. Bo-Nan , L. Bao-Liang 
\textit{Multimodal Emotion Recognition using EEG and Eye Tracking Data}, IEEE, 2014
\bibitem{LinMusic}
Y. P. Lin et al., "EEG-Based Emotion Recognition in Music Listening," in IEEE Transactions on Biomedical Engineering, vol. 57, no. 7, pp. 1798-1806, July 2010.
doi: 10.1109/TBME.2010.2048568
\url{http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5458075&isnumber=5484937}
\bibitem{GaoMehmood}
Y. Gao, H. J. Lee and R. M. Mehmood, "Deep learninig of EEG signals for emotion recognition," 2015 IEEE International Conference on Multimedia \& Expo Workshops (ICMEW), Turin, 2015, pp. 1-5.
doi: 10.1109/ICMEW.2015.7169796
\url{http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7169796&isnumber=7169738}
\bibitem{NieWangShiLu}Dan Nie, Xiao-Wei Wang, Li-Chen Shi, and Bao-Liang Lu, EEG-based Emotion Recognition during Watching Movies, Proceedings of the 5th International IEEE EMBS Conference on Neural Engineering Cancun, Mexico, April 27 - May 1, 2011 ,\url{https://pdfs.semanticscholar.org/6511/590bc9677922c82747b5d183383f46b50db6.pdf}


\end{thebibliography}



\end{document}


